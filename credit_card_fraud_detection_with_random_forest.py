# -*- coding: utf-8 -*-
"""credit-card-fraud-detection-with-random-forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/148JVQLS3aT3z1RvIhjweBQwYA-s__DfM
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import missingno as msno
import datetime as dt

csv_path_train="/kaggle/input/fraud-detection/fraudTrain.csv"
data=pd.read_csv(csv_path_train)
df_train=pd.DataFrame(data)
df_train.head(2)

csv_path_test="/kaggle/input/fraud-detection/fraudTrain.csv"
data=pd.read_csv(csv_path_test)
df_test=pd.DataFrame(data)
df_test.head(2)

df_train.info()

df_test.info()

"""# Exploratory Data Analysis (EDA)"""

df_train.isnull().sum()

df_test.isnull().sum()

df_train.describe()

df_test.describe()

df_train["is_fraud"].value_counts()

df_test["is_fraud"].value_counts()

msno.matrix(df_train)

df_train["amt"].describe()

donut = df_train["is_fraud"].value_counts().reset_index()

labels = ["No", "Yes"]
explode = (0, 0)

fig, ax = plt.subplots(dpi=120, figsize=(8, 4))
plt.pie(donut["is_fraud"],
        labels=donut["is_fraud"],
        autopct="%1.1f%%",
        pctdistance=0.8,
        explode=explode)

centre_circle = plt.Circle((0.0, 0.0), 0.5, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.title("Fraud proportion in Transactions")
plt.legend(labels, loc="center", frameon=False)
plt.show();

sns.countplot(x="category",data=df_train)
plt.title("category distribution")
plt.xticks(rotation=90)
plt.show()

plt.figure(figsize=(10,5))
# Group by "TransactionType" and calculate the mean of "isFraud"
fraud_percentage_by_category = df_train.groupby('category')['is_fraud'].mean() * 100
# Create a bar plot
plt.bar(fraud_percentage_by_category.index, fraud_percentage_by_category.values)
# Adding labels and title
plt.xlabel('Transaction category ')
plt.ylabel('Fraud Percentage category')
plt.title('Fraud Percentage by category')

# Rotate x labels for better readability
plt.xticks(rotation=45)

plt.show()

df_train['age'] = dt.date.today().year-pd.to_datetime(df_train['dob']).dt.year
ax = sns.kdeplot(x='age', data=df_train, hue='is_fraud', common_norm=False)
ax.set_xlabel('Credit Card Holder Age')
ax.set_ylabel('Density')
plt.xticks(np.arange(0, 110, 10))
plt.title('Age Distribution')
plt.legend(title='Type', labels=['Fraud', 'Not Fraud']);

df_train['hour'] = pd.to_datetime(df_train['trans_date_trans_time']).dt.hour
f, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 6), sharey=True)
ax1 = sns.histplot(x='hour', data=df_train[df_train["is_fraud"] == 0],
                   stat="density", bins=24, ax=ax1)
ax2 = sns.histplot(x='hour', data=df_train[df_train["is_fraud"] == 1],
                   stat="density", bins=24, ax=ax2, color="blue")
ax1.set_title("Normal")
ax2.set_title("Fraud")
ax1.set_xticks(np.arange(1, 24))
ax2.set_xticks(np.arange(1, 24));

df_train['month'] = pd.to_datetime(df_train['trans_date_trans_time']).dt.month
f, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 6), sharey=True)
ax1 = sns.histplot(x='month', data=df_train[df_train["is_fraud"] == 0],
                   stat="density", bins=12, ax=ax1)
ax2 = sns.histplot(x='month', data=df_train[df_train["is_fraud"] == 1],
                   stat="density", bins=12, ax=ax2, color="blue")
ax1.set_title("Normal")
ax2.set_title("Fraud")
ax1.set_xticks(np.arange(1, 13))
ax2.set_xticks(np.arange(1, 13));

"""# Feature engineering"""

df_train.drop(columns=["merchant", "first", "last", "street","unix_time", "trans_num","month","age","hour"], inplace=True)
df_test.drop(columns=["merchant", "first", "last", "street","unix_time", "trans_num"], inplace=True)
print(df_train.shape)
print(df_test.shape)

#training data
x_train=df_train.drop("is_fraud",axis=1)
y_train=df_train["is_fraud"]



#testing data
x_test=df_test.drop("is_fraud",axis=1)
y_test=df_test["is_fraud"]
x_train.info()
print(x_train.shape)
print(x_test.shape)



"""**pipeline creation**"""

from sklearn.pipeline import Pipeline
from sklearn.preprocessing import MinMaxScaler,OneHotEncoder

#numerical features
num_feats=x_train.drop(["trans_date_trans_time","category","gender","city","state","job","dob"],axis=1)
num_feats_pipe=Pipeline([
    ("scalar",MinMaxScaler())
    ])
num_feats_preprocessed=num_feats_pipe.fit_transform(num_feats)

#catagorical features
cat_feats=x_train[["trans_date_trans_time","category","gender","city","state","job","dob"]]
cat_feats_pipe=Pipeline([
    ("encoder",OneHotEncoder())
    ])
cat_feats_preprocessed=cat_feats_pipe.fit_transform(cat_feats)
print(num_feats)

"""**final pipeline**"""

from sklearn.compose import ColumnTransformer
num_list=list(num_feats)
cat_list=list(cat_feats)

final_pipeline=ColumnTransformer([
    ("num",num_feats_pipe,num_list),
    ("cat",cat_feats_pipe,cat_list)])
X_train_preprocessed=final_pipeline.fit_transform(x_train)
print(df_train)
X_train_preprocessed

X_test_preprocessed = final_pipeline.fit_transform(x_test)
X_test_preprocessed

"""# Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

# Create a Random Forest classifier
rf_model = RandomForestClassifier(n_estimators=50, random_state=21)

# Train the model on your training data
rf_model.fit(X_train_preprocessed,y_train)

# Make predictions on your testing data
y_test_pred_rf = rf_model.predict(X_test_preprocessed)

# Make predictions on your training data
y_train_pred_rf = rf_model.predict(X_train_preprocessed)
y_train_pred_rf
y_test_pred_rf

"""**F1 score of train and test**"""

from sklearn.metrics import f1_score
f1 = f1_score(y_train,y_train_pred_rf)
print("F1 Score of train data:", f1)

f2 = f1_score(y_test,y_test_pred_rf)
print("F1 Score of test data:", f2)

from sklearn.metrics import classification_report
report = classification_report(y_test, y_test_pred_rf)
print(report)

"""**Train Confusion Matrix**"""

from sklearn.metrics import confusion_matrix

# Compute the confusion matrix
cm = confusion_matrix(y_train, y_train_pred_rf)

# Create a heatmap to visualize the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicted Labels ")
plt.ylabel("True Labels ")
plt.title(" Train Confusion Matrix")
plt.show()

"""**Test Confusion Matrix**"""

from sklearn.metrics import confusion_matrix

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_test_pred_rf)

# Create a heatmap to visualize the confusion matrix
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.xlabel("Predicted Labels ")
plt.ylabel("True Labels ")
plt.title(" Test Confusion Matrix")
plt.show()

